
\section{Experimental Results}

We conducted a comprehensive evaluation of CD-KAN against seven state-of-the-art baselines across ten diverse datasets, assessing both causal discovery performance and forecasting accuracy.

\subsection{Datasets}
To ensure robustness, we utilized a mix of synthetic and real-world datasets:

\begin{itemize}
    \item \textbf{Synthetic Linear (2 datasets)}: Generated via Vector Autoregression (VAR) with random sparse adjacency matrices. ($N=500, 2000$; Nodes=5).
    \item \textbf{Synthetic Nonlinear (2 datasets)}: Generated via Structural Causal Models (SCMs) with non-linear dependencies (sine, tanh). ($N=500, 2000$; Nodes=5).
    \item \textbf{Financial (8 Assets)}: Daily closing prices of major assets (Gold, Oil, S\&P500, BTC, etc.) from 2020-2025 ($N=1827$).
    \item \textbf{Cryptocurrency (5 Coins)}: Top 5 cryptocurrencies by market cap ($N=1095$).
    \item \textbf{Macroeconomic (5 Indicators)}: Key economic indicators including inflation and interest rates ($N=1257$).
    \item \textbf{Energy Grid (12 Nodes)}: Time series of power load across different grid nodes ($N=5000$).
    \item \textbf{Climate Sensors (15 Nodes)}: Environmental sensor data ($N=5000$).
\end{itemize}

\subsection{Baselines and Experimental Setup}
We compared CD-KAN against a rigorous set of baselines:
\begin{enumerate}
    \item \textbf{VAR-Lasso}: Linear baseline with L1 regularization.
    \item \textbf{PCMCI}: State-of-the-art constraint-based method.
    \item \textbf{NTiCD}: Neural Time-invariant Causal Discovery.
    \item \textbf{GOLEM}: Continuous optimization for DAG learning.
    \item \textbf{NOTEARS} / \textbf{DYNOTEARS}: Differentiable structure learning methods.
    \item \textbf{TSMixer/LSTM}: Pure forecasting baselines (for predictive comparison).
\end{enumerate}

\subsection{Causal Discovery Performance}

Table \ref{tab:causal_results} summarizes the Causal Discovery performance. CD-KAN achieves SOTA results with a mean F1-score of \textbf{0.8971}, significantly outperforming the best baseline (PCMCI, F1=0.6550).

\begin{table}[h]
\centering
\caption{Comparative Analysis of Causal Discovery Performance (Mean Metrics across 10 Datasets)}
\label{tab:causal_results}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccc}
\hline
\textbf{Algorithm} & \textbf{Mean F1 Score} $\uparrow$ & \textbf{Mean SHD} $\downarrow$ & \textbf{Precision} $\uparrow$ & \textbf{Recall} $\uparrow$ \\ \hline
\textbf{CD-KAN (Ours)} & \textbf{0.8971} & \textbf{1.40} & \textbf{0.87} & \textbf{0.92} \\
PCMCI & 0.6550 & 10.60 & 0.62 & 0.71 \\
VAR-Lasso & 0.6434 & 7.60 & 0.58 & 0.75 \\
NTiCD & 0.5939 & 10.40 & 0.55 & 0.68 \\
NOTEARS & 0.5075 & 15.40 & 0.48 & 0.55 \\
GOLEM & 0.4954 & 15.00 & 0.45 & 0.52 \\ \hline
\end{tabular}
}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/cdkan_sota_comprehensive_results.png}
    \caption{Comprehensive performance analysis of CD-KAN vs. Baselines. (Top-Left) Average F1 scores showing CD-KAN dominance. (Top-Right) Per-dataset F1 comparison. (Bottom-Left) Runtime scalability O(N). (Bottom-Right) Precision-Recall trade-off.}
    \label{fig:comprehensive_results}
\end{figure}

As shown in Figure \ref{fig:comprehensive_results}, CD-KAN demonstrates superior scalability and precision-recall balance. Importantly, it reduces Structural Hamming Distance (SHD) by 81\% compared to VAR-Lasso, indicating far fewer false positives and missed edges.

Figure \ref{fig:heatmap} provides a granular view of performance across all datasets, highlighting CD-KAN's consistent superiority (top row).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/cdkan_sota_heatmap.png}
    \caption{Heatmap of F1 Scores across all Algorithm-Dataset pairs. CD-KAN (top row) consistently achieves high performance (green) across diverse data types, whereas baselines struggle (yellow/red) in non-linear or complex scenarios.}
    \label{fig:heatmap}
\end{figure}

\subsection{Forecasting Performance}

Beyond causal discovery, CD-KAN delivers exceptional forecasting accuracy. On the challenging Financial dataset, CD-KAN achieves an MSE of \textbf{0.0008}, outperforming TSMixer by an order of magnitude.

\begin{table}[h]
\centering
\caption{Forecasting Performance (Financial Dataset, N=1827)}
\label{tab:forecasting_results}
\begin{tabular}{lcc}
\hline
\textbf{Model} & \textbf{MSE} $\downarrow$ & \textbf{MAE} $\downarrow$ \\ \hline
\textbf{CD-KAN (Ours)} & \textbf{0.0008} & \textbf{0.0203} \\
TSMixer (SOTA Baseline) & 0.0178 & 0.1079 \\
LSTM & 0.0620 & 0.2120 \\
Naive KAN & 0.0550 & 0.1829 \\ \hline
\end{tabular}
\end{table}

\subsection{Ablation Study}
To validate our design choices, we analyzed the contribution of key components:
\begin{itemize}
    \item \textbf{w/o ALM}: F1 score drops to 0.72, as soft constraints fail to enforce strict acyclicity.
    \item \textbf{w/o RevIN}: Forecasting MSE degrades to 0.015, highlighting the importance of handling non-stationarity.
    \item \textbf{w/o KAN (using MLP)}: F1 score on nonlinear data drops to 0.58, confirming the value of learnable activation functions for complex dependencies.
\end{itemize}
